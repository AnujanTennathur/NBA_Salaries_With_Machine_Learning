---
title: "regression 2003 nba"
author: "Jack Carr"
date: "2025-04-04"
output: html_document
---


```{r setup, include=FALSE}
library(knitr)
library(tidyverse)
library(moderndive)
library(caret)
library(mgcv)
library(rpart)
library(rpart.plot)
library(dplyr)
```


## Uncomment this chunk and delete the above
```{r}
clean_nba03 <- read_csv("complete_nba_2003.csv")
```


## Ression with the 2003 data set
```{r}
# More cleaning
colnames(clean_nba03)[colnames(clean_nba03) == "X2002.03"] <- "salary"
clean_nba03$salary <- as.numeric(gsub("[$,]", "", clean_nba03$salary))
```


```{r}
set.seed(123)
# Training Set, 316 * 0.7 = 221.2 = 221 

train_set = sample(1:316, 221)
salary03_1 = clean_nba03[train_set,]

ggplot(salary03_1, aes(x=pts_per_g, y=salary)) + geom_point() + 
  geom_smooth(method = "lm", se = FALSE)
```

## Parallel Slopes Model
```{r}
# Parallel Slopes Model 
p_slope_mdl = lm(salary~pos + pts_per_g, data = salary03_1)

ggplot(salary03_1, aes(x=pts_per_g, y=salary, color=pos)) + 
  geom_point() + 
  geom_parallel_slopes(se=FALSE)
```

## Multiple Linear Regression Model
```{r}
# Multiple Linear Model + Interaction
# 2 Different explanatory variables: PTS, Position
mult_lin_mdl = lm(salary~pos*pts_per_g, data = salary03_1)
#summary(mult_lin_mdl)
#mult_lin_mdl$coefficients

# Visualization 
ggplot(salary03_1, aes(x=pts_per_g, y=salary, color=pos)) + 
  geom_point(alpha=0.3) + 
  geom_smooth(method="lm", se=FALSE)
```

# Caret Package Models

## Regression Trees Pt1 - Complexity x RMSE

``` {r}
set.seed(123)

trctrl <- trainControl(method = "repeatedcv", number = 10, repeats = 10)

caretTree  <-  train(salary ~ pos + team_id + age + pts_per_g + per + ws + obpm,
                    data = clean_nba03,
                    method = "rpart",
                    trControl=trctrl,
                    tuneGrid = expand.grid(cp=seq(0, 0.01, 0.0001))
)

plot(caretTree)

```

## Regression Trees Pt2 - Tree

``` {r}
rpart.plot(caretTree$finalModel)

```

## Regression Trees Pt3 - Cross Validation Results
``` {r}

caretTree$results[caretTree$results$cp==caretTree$bestTune[1,1], ]
```

## Multiple Linear Model Cross Validation
``` {r}
# Linear Model
set.seed(123)

trctrllm <- trainControl(method = "repeatedcv", number = 5, repeats = 10)

caretLM<-  train(salary ~ age + pts_per_g, # removed categorical variables
                  data = clean_nba03,  
                  method = "lm",
                  trControl=trctrllm
)
```

``` {r}
caretLM$results
```

# GAM & Polynomial Models

## GAM Model 1

``` {r}
mod_gam = gam(salary ~ s(pts_per_g) + age, data = clean_nba03)
ggplot(clean_nba03, aes(x=pts_per_g, y=salary))+
  geom_point()+
  geom_line(aes(y=mod_gam$fitted.values), color="cyan", size=1)+
  ggtitle("GAM Model 1")
```

## Cross Validated Results: GAM Model 1

``` {r}
set.seed(123)

trctrlgam <- trainControl(method = "repeatedcv", number = 5, repeats = 10)

caretgam<-  train(salary ~ age + pts_per_g, # removed categorical variables
                  data = clean_nba03,  
                  method = "gam",
                  trControl=trctrlgam
)

caretgam$results
```

## GAM Model 2

``` {r}
mod_gam2 <- gam(salary ~ s(pts_per_g), data = clean_nba03)
ggplot(clean_nba03, aes(x=pts_per_g, y=salary))+
  geom_point()+
  geom_line(aes(y=mod_gam2$fitted.values), color="red4", size=1)+
  ggtitle("GAM Model 2")
```


## Cross Validated Results: GAM Model 2

``` {r}

set.seed(123)

trctrlgam2 <- trainControl(method = "repeatedcv", number = 5, repeats = 10)

caretgam2<-  train(salary ~ pts_per_g, # removed categorical variables
                  data = clean_nba03,  
                  method = "gam",
                  trControl=trctrlgam2
)

caretgam2$results
```

## Polynomial Models -- PTS & Salary

``` {r}
## DEGREE 1: Linear Model
model_1 <- lm(salary ~ poly(pts_per_g,1), data = clean_nba03)

ggplot(clean_nba03, aes(x=pts_per_g, y=salary))+
  geom_point()+
  geom_line(aes(y=model_1$fitted.values), color="red", size=1)+
  ggtitle("Degree 1")
```

## Degree 2
``` {r}
## Degree 2: Quadratic
model_2 <- lm(salary ~ poly(pts_per_g,2), data = clean_nba03)

ggplot(clean_nba03, aes(x=pts_per_g, y=salary))+
  geom_point()+
  geom_line(aes(y=model_2$fitted.values), color="green4", size=1)+
  ggtitle("Degree 2")
```

## Degree 3: Cubic
``` {r}
model_3 <- lm(salary ~ poly(pts_per_g,3), data = clean_nba03)

ggplot(clean_nba03, aes(x=pts_per_g, y=salary))+
geom_point()+
  geom_line(aes(y=model_3$fitted.values), color="green4", size=1)+
  ggtitle("Degree 3")
```

## Degree 5
``` {r}
model_5 <- lm(salary ~ poly(pts_per_g,5), data = clean_nba03)

ggplot(clean_nba03, aes(x=pts_per_g, y=salary))+
geom_point()+
  geom_line(aes(y=model_5$fitted.values), color="green4", size=1)+
  ggtitle("Degree 5")
```

## Degree 10
``` {r}
model_10 <- lm(salary ~ poly(pts_per_g,10), data = clean_nba03)

ggplot(clean_nba03, aes(x=pts_per_g, y=salary))+
geom_point()+
  geom_line(aes(y=model_10$fitted.values), color="green4", size=1)+
  ggtitle("Degree 10")
```

## Significance
``` {r}
summary(model_3)
```

## Cross Validated Results

``` {r}

set.seed(123)

trctrlpoly <- trainControl(method = "repeatedcv", number = 5, repeats = 10)

caretpoly<-  train(salary ~ poly(pts_per_g, 2),
                  data = clean_nba03,  
                  method = "lm",
                  trControl=trctrlpoly
)

caretpoly$results
```







