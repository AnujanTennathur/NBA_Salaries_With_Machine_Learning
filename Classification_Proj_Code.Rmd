---
title: "Classification_Project_Code_NBA"
author: "AJ Tennathur"
date: "2025-04-01"
output:
  html_document: default
  pdf_document: default
---

``` {r}
library(knitr)
library(tidyverse)
library(moderndive)
library(caret)
library(mgcv)
library(rpart)
library(rpart.plot)
library(GGally)
library(ipred)
library(vip)
library(randomForest)
library(xgboost)
```

# Data Wrangling/Viz

``` {r}
ggpairs(salary, aes(color = Position), columns = c(3,4,5))
```

# Background

-- We are now looking at classification machine learning models for our 2022-2023 
NBA dataset. Later, we will also examine the earlier 2002-2003 NBA season, which we also 
do for our Regression Modeling. 
-- Our goal is to use machine learning classification models to predict player position
(Point Guard, Shooting Guard, Center, Etc.) based on various explanatory variables.

# KNN 

-- As part of our classification analysis, we will start with our 
K-Nearest Neighbors, or KNN, analysis. 
-- Important note: higher k values may lead to under fitting with more of a bias
towards general trends and relative resistance, while very small k values are prone to over fitting and being very sensitive to outlying data.
 

# Standardize
``` {r}
# use scale to standardize
salary_2=salary
salary_2[,25:31] =scale(salary_2[,25:31])
salary_2=data.frame(salary_2)

salary_2$Position = as.factor(salary_2$Position)

# now check the standardized variance
sd(salary_2[ ,25])
sd(salary_2[ ,31])
```

# Visualize

``` {r}
ggpairs(salary_2, aes(color = Position), columns = c(25,26,27,28,29, 30, 31))
```

``` {r}
ggplot(data = salary_2, aes(x = AST, y = TRB, col = Position)) + 
  geom_point(alpha=0.3)
```

``` {r}
set.seed(239)

PG= salary_2%>%
  filter(Position=="PG")

SG= salary_2%>%
  filter(Position=="SG")

SF= salary_2%>%
  filter(Position=="SF")

PF= salary_2%>%
  filter(Position=="PF")

C= salary_2%>%
  filter(Position=="C")

# 50 observations from each
# Take 60% to train (30) and 40% to test (20)
trainnba = sample(1:50, 30)

nba.train= rbind(PG[trainnba,], SG[trainnba,], SF[trainnba,], PF[trainnba,], C[trainnba,])
nba.test= rbind(PG[-trainnba,], SG[-trainnba,], SF[-trainnba,], 
                   PF[-trainnba,], C[-trainnba,])
```


``` {r}
library(class)
knnNBA= knn(train = nba.train[,25:31], 
              test = nba.test[,25:31], 
              cl = nba.train$Position, 
              k = 16)
## correct
mean(knnNBA==nba.test$Position)
mean(knnNBA!=nba.test$Position)
```

# Cross Validation

``` {r}
error = rep(0,20)
for (i in 1:20) {
  knnNBA= knn(train = nba.train[,25:31], test = nba.test[,25:31], cl = nba.train$Position, k = i)
  error[i] = 1- mean(knnNBA == nba.test$Position)
}

plot_data = data.frame(k=1:20,error)

ggplot(data = plot_data, aes(x = k, y = error)) +
  geom_line(color = "blue")+
  xlab("Neighborhood Size")
```

``` {r}
best_k = which.min(error)
best_k
```

# Prediction with best k

``` {r}
nba_pred = knn(train = nba.train[,25:31], 
                 test = nba.test[,25:31], 
                 cl = nba.train$Position, 
                 k=19)

table(nba.test$Position, nba_pred)

mean(nba_pred==nba.test$Position)

```

# KNN Model Conclusions



# Classification/Decision Trees

-- Next, we will do classification machine learning modeling through classification/decision trees. 

``` {r}
library(caret)

caretSampnba_2 = createDataPartition(salary_2$Position,
                                     p = 0.7, 
                                     list = FALSE)

traincaretnba_2 = salary_2[caretSampnba_2,]
testcaretnba_2 = salary_2[-caretSampnba_2,]

traincaretnba_2 = traincaretnba_2 %>%
  select(
    "Position", "TRB", "AST", "STL", "BLK", "PTS", "TOV", "PER", "OBPM", "FT", "FTA", 
    "X2P", "X2PA", "X3P", "X3PA", 
  )

testcaretnba_2 = testcaretnba_2 %>%
  select(
    "Position", "TRB", "AST", "STL", "BLK", "PTS", "TOV", "PER", "OBPM", "FT", "FTA", 
    "X2P", "X2PA", "X3P", "X3PA", 
  )

```

``` {r}
library(rpart)

classtree = rpart(Position ~ ., 
                  data = traincaretnba_2, 
                  method = "class")
rpart.plot(classtree)

```

```{r}
plotcp(classtree)
printcp(classtree)
```

``` {r}
minCP=classtree$cptable[which.min(classtree$cptable[,"xerror"]),"CP"]
minCP
```

  # Prune Tree

``` {r}
prune_classtree = prune(classtree, cp = 0.047)
rpart.plot(prune_classtree)
```

  # Classification Trees -- Predictions 

# Default Tree
``` {r}
predTree1=predict(classtree, testcaretnba_2, type="class")

cmTree1=table(testcaretnba_2$Position, predTree1)
cmTree1

mean(testcaretnba_2$Position==predTree1)
```
# Prune Tree

``` {r}
predTree2=predict(prune_classtree, testcaretnba_2, type="class")

### CONFUSION MATRIX
cmTree2=table(testcaretnba_2$Position, predTree2)
cmTree2

#### CORRECT RATE
mean(testcaretnba_2$Position==predTree2)
```

# Classification Tree(s) Conclusions



# Bagging
  -- While classification decision trees give us a general view of our model, 
  another method that is effective is Bagging, which stands for 
  “bootstrap aggregation”. 
  -- Random bootstrap samples (with replacement) of the data are used to create trees.
  -- It then aggregates these different trees (that are based on different subset samples) to create a final model. 
  -- The big idea is that averaging a set of observations reduces variance.

-- ipred library

``` {r}
### BAG
set.seed(252)
pimaBag = bagging(Position ~ .,
                   data = traincaretnba_2,
                   nbagg = 150,   
                   coob = TRUE,
                   control = rpart.control(minsplit = 2, cp = 0))

## PREDICT
predBag=predict(pimaBag, testcaretnba_2, type="class")

## CONFUSION MATRIX
cmBag=table(testcaretnba_2$Position, predBag)
cmBag

mean(testcaretnba_2$Position==predBag) # correct rate
```
# Repeat with Caret

``` {r}
set.seed(252)
caretBag = train(Position ~., 
               data = traincaretnba_2, 
               method = "treebag",
               trControl = trainControl("cv", number = 10),
               importance = TRUE
)

predCaretBag = caretBag %>% predict(testcaretnba_2)

table(predCaretBag, testcaretnba_2$Position)

mean(predCaretBag == testcaretnba_2$Position) # Correct Rate

```


# Bag Variable Importance: Let's see which variables are having the largest 
"influence" on our model

``` {r}
vip(caretBag)
```

# Bagging Model Conclusions




# Random Forests

There are some problems with Bagging: 
- Trees can be very similar
- Dominated by a few strong / moderately strong predictor
- Bagged trees can be highly correlated
- Does not lead to large reduction in variance when averaging


-- We can further improve on bagging through random forests modeling. 

``` {r}
set.seed(250)

caretRF = train(Position ~., 
                data = traincaretnba_2, 
                method = "rf", 
                trControl = trainControl("cv", number = 10),
                importance = TRUE
          )
caretRF$bestTune
caretRF$finalModel
```
# predictions with RF

``` {r}
predCaretRF = caretRF %>% predict(testcaretnba_2)
table(predCaretRF, testcaretnba_2$Position)

mean(predCaretRF==testcaretnba_2$Position)
```

# Variable Importance: Let's see which variables are contributing to "splits" and 
which variables are reducing gini (impurity). 

``` {r}
varImpPlot(caretRF$finalModel, type = 1)
varImpPlot(caretRF$finalModel, type = 2)
```

# Random Forests Conclusions


# Boosting
-- Boosting is essentially growing the decision trees sequentially. 
-- The Model learns slowly (updates based on some scaled version of the previous tree). -- It tends to perform well, with each tree growing using information from previously grown trees. 


``` {r}
caretBoost = train(Position ~., 
                  data = traincaretnba_2, 
                  method = "xgbTree", 
                  trControl = trainControl("cv", number = 10),
                  importance = TRUE
          )

caretBoost$bestTune

```

``` {r}
predCaretBoost = caretBoost %>% predict(testcaretnba_2)
table(predCaretBoost, testcaretnba_2$Position)

mean(predCaretBoost == testcaretnba_2$Position)
```


# Boosting Conclusions



# Simple Logistic Regression
```{r}
modnba3 <- glm(court_group ~ PTS, data = traincaretnba_3, family = "binomial")
summary(modnba3)
```

Plot the model:
```{r}
# logistic
ggplot(data=traincaretnba_3, aes(x=PTS, y=court_group))+
  geom_point()+
  geom_line(aes(x = PTS, y = modnba3$fitted), color="blue")
```

#### Step 6: Interpretation

The estimate for the slope, $\beta_1$ is
```{r}
# slope
slopenba<-modnba3$coefficients[2]
slopenba
```

```{r}
# PREDICT (DEFAULT)
pred1<-predict(modnba3, newdata = testcaretnba_3)
head(pred1)
```

```{r}
# PREDICT (Response)
pred1R<-predict(modnba3, newdata = testcaretnba_3, type="response")
head(pred1R)
```

```{r}
## CONFUSION MATRIX
conf_mat2<-data.frame(testcourt_group=testcaretnba_3$court_group, predOut=pred1R>.3)
table(conf_mat2$predOut, conf_mat2$testcourt_group)

## CORRECT RATE
mean(conf_mat2$predOut==conf_mat2$testcourt_group)
```

# Multiple Logistic Regression

``` {r}
traincaretnba_3 = traincaretnba_2 %>%
  mutate(
    court_group = case_when(
      Position %in% c("PG", "SG") ~ 0, 
      Position %in% c("SF", "PF", "C") ~ 1
    )
  )

testcaretnba_3 = testcaretnba_2 %>%
  mutate(
    court_group = case_when(
      Position %in% c("PG", "SG") ~ 0, 
      Position %in% c("SF", "PF", "C") ~ 1
    )
  )

traincaretnba_3 = traincaretnba_3 %>%
  select(-Position)

traincaretnba_4 = traincaretnba_3 %>%
  select(TRB, AST, court_group)

```


``` {r}
modMulti<-glm(court_group ~.,
          data = traincaretnba_3, family = "binomial")

summary(modMulti)

```


``` {r}
library(bestglm)

# Backward Selection 
step(modMulti)

```


``` {r}
# Forward Selection 
mod0 = glm(court_group ~ 1, family = binomial, data = traincaretnba_3)

## FORWARD Selection
step(mod0, scope = list(upper = modMulti, lower = mod0), 
     method = "forward")
```



``` {r}
# Subset Selection 
best.Xy = traincaretnba_3

# Run best subset
bglm.AIC = bestglm(Xy = best.Xy, family = binomial, IC = "AIC", 
                   TopModels = 10)

bglm.AIC$BestModels

```

# Unfortunately, our three multiple logistic regression models do not give 
the same variable results. Thus, we have three different "best" models, which 
I will show below.

``` {r}
Mod_Best_forward = glm(court_group ~ BLK + AST + 
                         TRB + STL + X3P, 
                       data = traincaretnba_3, 
                       family = "binomial")

Mod_Best_backward = glm(court_group ~ TRB + AST + 
                         STL + PTS + FTA + X2PA + X3P, 
                       data = traincaretnba_3, 
                       family = "binomial")

Mod_Best_subset = glm(court_group ~ TRB + AST + 
                         STL + PTS + FTA + X2PA + X3P, 
                       data = traincaretnba_3, 
                       family = "binomial")

```


# Prediction for three Multiple Logistic Regression Models

``` {r}
pred_best_forward = predict(Mod_Best_forward, newdata = testcaretnba_3, 
                            type="response")
conf_mat_forward = data.frame(testOutcome=testcaretnba_3$court_group, 
                             predOut=pred_best_forward>.5)
table(conf_mat_forward$predOut, conf_mat_forward$testOutcome)

```

``` {r}
pred_best_backward = predict(Mod_Best_backward, newdata = testcaretnba_3, 
                            type="response")
conf_mat_backward = data.frame(testOutcome=testcaretnba_3$court_group, 
                             predOut=pred_best_backward>.5)
table(conf_mat_backward$predOut, conf_mat_backward$testOutcome)

```

``` {r}
pred_best_subset = predict(Mod_Best_subset, newdata = testcaretnba_3, 
                            type="response")
conf_mat_subset = data.frame(testOutcome=testcaretnba_3$court_group, 
                             predOut=pred_best_subset>.5)
table(conf_mat_subset$predOut, conf_mat_subset$testOutcome)

```

# Let's compare the mean rates of accuracy of the three 
Multiple Logistic Regression Models 

``` {r}
mean(conf_mat_forward$predOut==conf_mat_forward$testOutcome)
mean(conf_mat_backward$predOut==conf_mat_backward$testOutcome)
mean(conf_mat_subset$predOut==conf_mat_subset$testOutcome)
```


# Multiple Logistic Regression Models Conclusions



# Linear Discriminant Analysis Model


``` {r}
library(MASS)

lda_pos = lda(court_group~., data = traincaretnba_4)

# Prediction 
pred_LDA = lda_pos %>% predict(testcaretnba_3)
mean(pred_LDA$class==testcaretnba_3$court_group)

```

``` {r}
plot(lda_pos)
```


``` {r}
library(klaR)
library(tidyverse)

traincaretnba_4$court_group = as.factor(traincaretnba_4$court_group)

partimat(court_group~., data = traincaretnba_4, method = "lda")

```


# Quadratic Discriminant Analysis Model

``` {r}
qda_pos = qda(court_group~., data = traincaretnba_4)
pred_QDA = qda_pos %>% predict(testcaretnba_3)
mean(pred_QDA$class==testcaretnba_3$court_group)

```


``` {r}
partimat(court_group~., data = traincaretnba_4, method = "qda")
```


# Linear/QDA Model Conclusions



# Overall Conclusions








